# NeoAgent 设计演进记录

## 2025-10-21: Agent 运行模式重构 —— 从 "Worker" 到 "Standalone + Cluster"

### 1. 演进背景 (Context)

**原始设计**:
Agent 被定义为分布式系统的末端执行单元，完全依赖 Master 节点的调度。
- 启动即监听 HTTP/gRPC 端口。
- 任务来源单一：仅接受 Master 下发的任务。
- 结果去向单一：仅回传给 Master。

**新需求**:
为了提高实用性和灵活性，Agent 需要支持独立运行模式（Standalone Mode）。
- 支持 CLI 命令行直接发起扫描（如 `./neoAgent scan -t 1.1.1.1`）。
- 开发调试时无需启动完整的 Master 集群。
- 支持作为单机安全工具分发。

### 2. 核心审查 (Linus Philosophy Check)

#### 2.1 Good Taste (品味)
- **现状**: 业务逻辑（Scanning Service）与通信层（HTTP Server）耦合过紧。
- **改进**: 将核心扫描逻辑剥离为纯粹的 `Core Service`，既可被 HTTP Handler 调用，也可被 CLI Command 调用。
- **结论**: 这种分层更清晰，提高了代码复用性，符合高内聚低耦合的原则。

#### 2.2 Pragmatism (实用主义)
- **解决的问题**:
    1.  开发调试繁琐：测试扫描逻辑需要启动全套集群。
    2.  使用场景受限：无法作为轻量级工具在现场环境快速使用。
- **结论**: 这是一个解决真实痛点的改动，而非过度设计。

#### 2.3 Never Break Userspace (向后兼容)
- **约束**: 现有的部署脚本和 Master 交互协议不能因本次改动而失效。
- **方案**: `neoAgent` 不带参数运行时，默认行为保持为启动 Server 模式（Cluster Worker），确保现有系统无缝兼容。

### 3. 架构演进方案 (Architecture Evolution)

#### 3.1 总体架构调整

**Before:**
```text
Main -> App (HTTP Server) -> Router -> Handler -> Service -> Executor
(Service 层严重依赖 Web 上下文)
```

**After:**
```text
Main (Cobra Entry)
 ├── "server" command (Default) -> Starts HTTP Server -> Calls Core Service
 └── "scan" command             -> Parses CLI Flags   -> Calls Core Service
      
Shared Core (internal/core)
 └── Service -> Executor
(Service 层纯粹化，不再感知是 HTTP 请求还是 CLI 命令)
```

#### 3.2 关键抽象

**1. 输入统一 (Input Abstraction)**
建立统一的 `Task Builder` 机制：
- **Cluster Mode**: HTTP JSON Body -> `Task Struct`
- **CLI Mode**: CLI Flags (`--target`, `--port`) -> `Task Struct`
核心 Service 只认 `Task Struct`，不关心来源。

**2. 输出解耦 (Output Abstraction)**
定义 `Reporter` 接口：
```go
type Reporter interface {
    Report(result *model.TaskResult) error
}
```
- **ClusterReporter**: 序列化 -> HTTP POST -> Master
- **ConsoleReporter**: 格式化 (Table/JSON) -> Stdout
- **FileReporter**: 序列化 -> Save to File

#### 3.3 目录结构规划

建议调整 `cmd` 和 `internal` 结构以适应新架构：

```text
neoAgent/
├── cmd/agent/
│   ├── main.go          # Cobra Root Command (入口)
│   ├── server.go        # Server 模式实现 (原 main 逻辑)
│   └── scan.go          # CLI 模式实现 (新逻辑)
├── internal/
│   ├── core/            # 核心业务 (原 Service 剥离)
│   │   ├── scanner.go   # 纯扫描逻辑
│   │   └── ...
│   ├── server/          # HTTP/gRPC 相关 (原 Handler/Router)
│   └── cli/             # CLI 辅助工具 (参数解析、结果打印)
```

### 4. 实施路线图

1.  **Refactor Core**: 将 `internal/app/agent` 中的 Service 逻辑解耦，移除对 `gin.Context` 等 Web 组件的依赖。
2.  **Introduce Cobra**: 引入 Cobra 库接管 `main.go`，将原启动逻辑封装为 Root Command。
3.  **Implement CLI**: 实现 `scan` 子命令，完成参数解析到 Task 的映射。
4.  **Verify**: 确保 `./neoAgent` 默认行为不变，`./neoAgent scan` 可独立工作。

---

## 2025-10-21: Agent 注册接入机制 —— Token + CA Hash

### 1. 需求分析
为了让 Standalone 模式的 Agent 能够平滑、安全地接入 Cluster，需要一个标准化的注册流程。
**安全痛点**:
- Master 如何验证接入的 Agent 身份？(AuthN)
- Agent 如何验证连接的 Master 身份？(防止 MITM)
- 如何避免复杂的 PKI 证书分发流程？

### 2. 方案设计 (The Join Protocol)

采用类似 Kubernetes `kubeadm join` 的 **Join Token** 机制。

#### 2.1 核心流程
1.  **Token Generation**: 管理员在 Master 生成有时效性的 Token。
2.  **Join Request**: Agent 使用 Token 发起 HTTPS 请求。
3.  **Credential Exchange**: Master 验证通过后，颁发长期有效的专属凭证（AgentID + APIKey/Cert）。
4.  **Persistence**: Agent 保存凭证，后续通信不再依赖 Token。

#### 2.2 CLI 设计
```bash
neoAgent join <master-addr> --token <token> [--ca-cert-hash <hash>]
```
- `--token`: 门票，用完即焚（或过期失效）。
- `--ca-cert-hash`: Master 身份指纹，防止中间人攻击。

### 3. 决策记录
- **放弃** 复杂的 CSR (证书签名请求) 手动审批流程，改为 Token 自动审批。
- **放弃** 预共享长期密钥 (Pre-shared Key) 模式，因为难以撤销和审计。
- **采纳** "信任首次使用" (TOFU) 的变体 —— 首次连接时通过 Token 互信，之后切换到强认证。

详细规范参见: [Agent注册流程说明.md](../Agent注册流程说明.md)

---

## 2025-10-21: 扫描能力建设 —— Build vs Buy 决策

### 1. 核心问题
Agent 作为一个扫描器，是应该完全依赖外部工具（如 Nmap, Nuclei），还是应该原生实现扫描能力？

### 2. 决策标准 (Native First, Wrapper Second)

为了兼顾性能、部署便捷性和生态丰富度，采用 **混合模式 (Hybrid Mode)**。

#### 2.1 基础原子能力 (Must Build Native)
**定义**: 逻辑简单、协议标准、无需庞大规则库的高频操作。
**决策**: **Go 原生实现**。
- **Host Discovery**: ICMP/ARP/TCP Ping (避免调用系统 ping 命令)。
- **Port Scan**: SYN/Connect Scan (Go 高并发优势)。
- **Service Banner**: 简单的 Socket 读写和正则匹配。
- **Web Fingerprint**: 基于 HTTP Header/Body 的关键词匹配。
- **Proxy/Tunnel**: SOCKS5/HTTP 代理服务 (Go 标准库优势)。

#### 2.2 复杂协议能力 (Build if Possible)
**定义**: 协议交互复杂但规则固定的操作。
**决策**: **优先 Go 原生实现**。
- **Brute Force**: SSH/Redis/MySQL/PostgreSQL 等常见服务使用 Go 官方/社区驱动进行爆破。

#### 2.3 生态依赖能力 (Must Wrap)
**定义**: 核心价值在于庞大的、高频更新的规则库/POC库。
**决策**: **外部工具调用 (Wrapper)**。
- **Vulnerability Scanning**: 调用 `Nuclei` (二进制或库)。
- **Reason**: 避免重复造轮子维护海量 POC。

### 3. 架构调整
在 `internal/core` 中引入 `Provider` 模式，允许同时存在原生实现和外部工具封装。

```go
type PortScanner interface {
    Scan(target string, ports []int) ([]Result, error)
}
// 优先使用 Native
type NativePortScanner struct {} 
// 特殊情况使用 Nmap
type NmapPortScanner struct {}
```

---

## 2025-10-21: 第三方工具集成策略 —— Battery Included

### 1. 核心理念
**"Battery Included, but Plug-in Compatible"**
Agent 应追求极致的 **单文件部署 (Single Binary)** 体验。

### 2. 集成清单与决策

#### 2.1 🚫 拒绝调用 (Native Replacement)
- **Masscan/Fscan**: 功能简单，Go 原生实现更优。
- **HTTPx/Dirsearch/Web爬虫**: 直接引用 Go 库或原生实现。

#### 2.2 ⚠️ 谨慎调用 (Optional Wrapper)
- **Nmap**: 仅在需要深度 OS 指纹识别时可选开启。
- **Hydra**: 仅在需要爆破冷门协议时可选开启。

#### 2.3 ✅ 必须集成 (Core Integration)
- **Nuclei**: 核心漏洞扫描引擎。
- **Chromium**: 现代 Web 扫描 (Headless)。
- **Yara**: 恶意软件检测。

详细规范参见: [第三方扫描工具调用.md](../第三方扫描工具调用.md)

---

## 2025-10-21: 并发模型选择 —— Semaphore vs Worker Pool

### 1. 决策
采用 **Semaphore (Channel) + WaitGroup** 模式，放弃复杂的 Worker Pool 模式。

### 2. 理由 (The "Simple is Better" Argument)
- **Go 哲学**: Goroutine 创建成本极低，不需要预先池化。
- **代码简洁**: 信号量模式代码量极少，逻辑清晰，无状态维护负担。
- **资源效率**: 无空转 Goroutine，闲置资源占用为 0。

### 3. 增强策略 (Adaptive Limiter)
单纯的信号量可能导致 FD 耗尽，因此引入 **分层并发策略 (Hierarchical Concurrency)**：
- **L1 (Ping)**: 高并发 (5000+)
- **L2 (Port)**: 中并发 (2000)，受 FD 限制
- **L3 (Web)**: 低并发 (200)，受目标负载限制
- **L4 (Heavy)**: 极低并发 (10)，受本地资源限制

详细规范参见: [并发模型设计说明.md](../并发模型设计说明.md)

---

## 2025-10-22: 探测能力调整 —— 放弃 TCP SYN 扫描 (Back to Basics)

### 1. 决策
在 `IpAlive` 和 `PortScan` 模块中，**彻底移除** 对 TCP SYN (Raw Socket) 扫描的支持，回归纯粹的 TCP Connect (Full Connect) 扫描。

### 2. 理由 (Why Simple is Better)

#### 2.1 复杂度的陷阱
- **架构一致性割裂**: SYN 扫描强依赖 Linux Raw Socket，导致 Windows/Linux 代码逻辑完全分叉，维护成本高。
- **权限地狱**: SYN 扫描必须要求 Root 权限，这严重限制了 Agent 在容器、普通用户环境下的部署能力。
- **并发陷阱**: 在不引入全局 Reactor 架构的前提下，SYN 扫描在大规模网段下性能反而不如全连接扫描（惊群效应）。

#### 2.2 实用主义的胜利
- **性能误区**: 现代内核对 TCP 连接的处理极快，全连接扫描与 SYN 扫描在万级并发下的性能差距已微乎其微。
- **稳定性优先**: 依赖 `net.Dial` 利用了操作系统成熟的 TCP 协议栈，自带重传、拥塞控制，远比我们手搓的 Raw Packet 可靠。
- **隐蔽性伪命题**: 除非配合防火墙规则拦截 RST，否则简单的 SYN 扫描在流量特征上并不比全连接扫描隐蔽多少。

### 3. 结论
我们不需要成为下一个 Zmap。对于企业内网和资产发现场景，**TCP Connect Scan 是性价比最高的选择**。它简单、便携、足够快。

---

## 2026-01-23: CLI 交互优化与扫描引擎技术路线演进

### 1. CLI 交互优化 (User Experience)

#### 1.1 简写参数 (Shorthand Flags)
为了减少用户的输入负担，遵循行业惯例引入简写：
- `--resolve-hostname` -> `-r`: 快速开启反向解析。
- `--tcp-ports` -> `-p`: 快速指定端口列表。

#### 1.2 隐式行为优化
- **智能 TCP 开启**: 当用户指定 `-p 80,443` 时，即便没有显式添加 `-T` (TCP Scan)，程序也应自动推断并开启 TCP 探测，符合用户直觉。
- **输出格式统一**: 
  - 表头顺序调整为 `IP, Status, OS, RTT, TTL, Hostname`，符合阅读习惯。
  - RTT 统一单位为 `ms` 并保留两位小数，TTL 统一为整数，消除格式混乱。

### 2. 端口服务扫描引擎路线 (Port/Service Scanner)

#### 2.1 决策：采用 "gonmap" 仿写模式
**核心问题**: 如何实现高质量的端口服务识别？
**方案**: 借鉴 `qscan` 的 `gonmap` 实现，在 Agent 内部仿写 Nmap 的探测逻辑。
**理由**:
- **Nmap 逻辑成熟**: 经过数十年验证的探针发送顺序和指纹匹配规则。
- **覆盖全面**: 同时支持端口发现、服务版本识别、操作系统识别。
- **可扩展性**: 兼容 Nmap 的指纹库，生态优势巨大。

#### 2.2 实现策略
不是简单的代码拷贝，而是逻辑移植：
- 复用 Agent 现有的并发框架和网络库。
- 将 Nmap 的探针逻辑适配到 Agent 的 `Service` 层。

### 3. 指纹规则管理 (Fingerprint Rule Management)

#### 3.1 混合模式 (Hybrid Mode)
为了兼顾**独立运行能力**和**规则实时更新**，采用混合管理策略：

1.  **固有规则 (Built-in Rules)**:
    - **内容**: `nmap-service-probes` (服务指纹) 和 `nmap-os-db` (OS 指纹)。
    - **方式**: 通过 `go:embed` 打包进二进制文件。
    - **作用**: 确保 Agent 在离线或无 Master 连接时仍具备核心识别能力。

2.  **动态规则 (Dynamic Rules)**:
    - **内容**: Master 下发的 `AssetCPE` (Nmap 规则映射) 和 `AssetFinger` (Web 指纹)。
    - **方式**: Agent 启动后从 Master 同步，保存在内存或本地缓存。
    - **作用**: 补充最新指纹，支持自定义规则。

#### 3.2 规则桥接 (Rule Bridge)
需要在内部实现一个桥接层，将 Nmap 原生规则格式与 Master 的 `AssetCPE` 结构打通，使得 Agent 的匹配引擎可以同时消费这两种来源的规则。

### 4. 结论
我们正在构建一个**"内置 Nmap 灵魂，外接云端大脑"**的新一代扫描引擎。它既有传统工具的可靠性，又有云原生架构的灵活性。

---

## 2026-01-25: 端口服务扫描器优化与重构

### 1. 规则管理架构：静态保底 + 动态增强
**决策**: 采用 `go:embed` 静态编译与动态加载相结合的规则管理策略。
- **静态基础**: 将 `nmap-service-probes` 和 `nmap-custom-probes` 作为 `internal` 包的私有资源嵌入二进制，确保 Agent 在任何环境下的基础识别能力。
- **动态扩展**: 预留 `SetRules` 接口，支持 Master 下发规则热更新。
- **路径限制**: 鉴于 `go:embed` 不支持回溯路径，确立了“构建时复制”的工程规范，将规则源文件从 `rules/` 复制到 `internal/pkg/` 进行打包。

### 2. CLI 极简主义：废除 `service` 子命令
**决策**: 删除 `scan service` 子命令，将其功能合并至 `scan port -s`。
- **理由**: 功能重叠。`port -s` 已经完整覆盖了“发现端口并识别服务”的场景。
- **收益**: 减少用户认知负担，降低代码维护成本。

### 3. 状态语义修正
**决策**: 将扫描结果中的 `matched` 状态统一修正为 `open`。
- **问题**: 原设计中，服务识别成功后将状态改为 `matched`，这破坏了与 Nmap 标准（open/closed）的一致性，且容易引起误解。
- **修正**: 端口连通即为 `open`，服务信息作为补充字段，不再侵入状态定义。

### 4. 性能调优：TCP Connect Scan 的局限性
**发现**: 在高并发（Rate=1000）下，TCP 全连接扫描极易因网络拥塞或防火墙限制导致丢包（False Negative）。
- **验证**: 降低并发至 Rate=10 后，成功识别出之前漏报的端口。
- **对策**: 
    - **短期**: 建议全端口扫描时使用低并发（Rate <= 100）。
    - **长期**: 计划引入 SYN Scan (Raw Socket) 以突破性能瓶颈。

---

## 2026-01-27: 编排与原子能力的边界确认

### 1. 决策：保持原子能力独立性，拒绝提前耦合
**问题**: 用户提出希望在 `scan port` 命令中加入 `-o` (OS识别) 参数，实现类似 Nmap `-A` 的效果。
**分析**:
- **职责单一原则**: `scan port` 应专注于端口和服务，`scan os` 应专注于操作系统识别。
- **时机未到**: 目前处于 Phase 3 (原子能力建设)，尚未到 Phase 4 (全流程编排)。过早在原子命令中引入编排逻辑（如在 PortScanner 中调用 OsScanner）会导致代码耦合，增加未来重构成本。
**结论**: **拒绝**在 `scan port` 中加入 `-o` 参数。

### 2. 替代方案与演进路线
- **当前 (Phase 3)**: 保持 `scan port` 和 `scan os` 作为独立的原子命令。如果需要串联，建议使用 Shell 脚本或管道。
- **未来 (Phase 4)**: 通过新增 `scan run` (Orchestration Command) 来实现全流程编排。`PipelineRunner` 将负责优雅地串联 Port -> Output -> OS -> Vuln，实现 `neoAgent scan run -p ... -s -o` 的终局形态。


