# 嵌入式重构：Asset & Orchestrator 模块目录结构

## 1. 核心设计哲学
**"Evolution, not Revolution" (演进，而非革命)**

为了遵守 **"Never break userspace"** 的铁律，我们不进行大规模的目录结构迁移（不采用激进的 DDD 分层目录），而是将新的核心逻辑作为 **子模块 (Sub-modules)** 嵌入到现有的 MVC 架构中。

- **Handler 层**：保持不变，仅做路由转发。
- **Service 层**：作为逻辑容器，内部嵌入复杂的编排引擎和数据流水线。
- **Repo 层**：保持不变，扩展新的数据访问方法。
- **Pkg 层**：放置无业务依赖的通用适配器。

## 2. 目录结构预览

```text
neoMaster/
├── cmd/
│   └── master/
│       └── main.go           # 入口文件
│
├── internal/
│   ├── handler/              # [保持不变] 接入层 (Controller)
│   │   ├── orchestrator/     # 调度相关接口
│   │   │   ├── project.go    # 项目管理 API
│   │   │   └── workflow.go   # 工作流管理 API
│   │   └── asset/            # 资产相关接口
│   │       └── asset.go      # 资产查询/导出 API
│   │
│   ├── service/              # [业务层] - 核心逻辑嵌入点
│   │   ├── orchestrator/     # 调度服务域
│   │   │   ├── core/         # [NEW] 核心编排引擎 (The Brain)
│   │   │   │   ├── engine.go       # 状态机引擎 (Stage流转)
│   │   │   │   ├── scheduler.go    # 定时调度器 (Cron)
│   │   │   │   └── dispatcher.go   # 任务分发器 (Master->Agent)
│   │   │   ├── service.go    # [Existing] 对外 Service 接口 (Facade)
│   │   │   └── workflow.go   # [Existing] 现有业务逻辑
│   │   │
│   │   └── asset/            # 资产服务域
│   │       ├── pipeline/     # [NEW] 资产处理流水线 (The Pipeline)
│   │       │   ├── resolver.go     # 目标解析 (Input -> IPs)
│   │       │   ├── merger.go       # 资产合并 (ETL: New + Old -> Merged)
│   │       │   └── ingestion.go    # 入库逻辑 (Save to DB)
│   │       └── service.go    # [Existing] 对外 AssetService
│   │
│   ├── pkg/                  # [通用库] - 基础设施嵌入点
│   │   ├── tool_adapter/     # [NEW] 扫描工具适配层 (Infrastructure)
│   │   │   ├── factory/      # 命令生成工厂
│   │   │   ├── parser/       # 结果解析器接口
│   │   │   └── registry/     # 工具注册中心
│   │   │
│   │   └── policy/           # [NEW] 策略通用库
│   │       ├── whitelist.go  # 白名单校验逻辑
│   │       └── scope.go      # 作用域校验逻辑
│   │
│   ├── repo/                 # [持久层] - 扩展支持新模型
│   │   ├── orchestrator/     # Project, Workflow, ScanStage Repo
│   │   └── asset/            # AssetHost, AssetNetwork, StageResult Repo
│   │
│   └── model/                # [模型层] - 定义核心数据结构
│       ├── orchestrator/     # Project, Workflow, ScanStage, Task
│       └── asset/            # AssetHost, AssetWeb, AssetNetworkScan
│
└── docs/                     # 文档
```

## 3. 关键模块说明

### 3.1 Service 层嵌入 (The "Guts")

我们不在 `service` 目录下堆砌文件，而是建立子目录来隔离复杂性：

- **`service/orchestrator/core/`**: 
  - 这是调度系统的"大脑"。它不直接处理 HTTP 请求，只负责状态流转。
  - `engine.go`: 处理 `Pending -> Running -> Finished` 的状态变迁。
  - `dispatcher.go`: 负责将 `ScanStage` 转换为 `Task` 并下发给 Agent。

- **`service/asset/pipeline/`**:
  - 这是资产处理的"流水线"。
  - `resolver.go`: 将 `192.168.1.1/24` 解析为具体的 IP 列表。
  - `merger.go`: 核心去重逻辑。比如，发现一个新端口，是覆盖旧数据还是追加？逻辑都在这里。

### 3.2 Pkg 层嵌入 (The "Tools")

- **`pkg/tool_adapter/`**:
  - 这是一个纯粹的工具库，不依赖任何业务逻辑（不引用 service 或 model）。
  - 它只关心：输入配置 -> 生成命令行字符串 -> 解析输出文本。
  - 这样设计是为了方便单元测试，也方便未来拆分微服务。


## 4. 详细模块映射说明

### 1. Control Plane (大脑) -> `internal/service/orchestrator/core`
我们将原来的"上帝类"拆解为原子组件，放在 `core` 子包下：
*   **scheduler**: 负责 "When to run"。解析 Cron，生成触发事件。
*   **engine**: 负责 "What to run next"。这是**状态机**的栖息地。输入当前 Stage 状态，输出下一个 Stage。
*   **dispatcher**: 负责 "Where to run"。调用 `repo` 获取可用 Agent，分配任务。

### 2. Data Plane (流水线) -> `internal/service/asset/pipeline`
资产处理不再是简单的 CRUD，而是一条流水线：
*   **resolver.go**: 实现 `Resolve(target)`。如果是动态解析，它会去查询数据库；如果是静态，直接拆解 CIDR。
*   **merger.go**: 实现 `Merge(newResult)`。这是处理数据冲突（Conflict Resolution）的地方。

### 3. Infrastructure (基石) -> `internal/pkg/tool_adapter`
这是最独立的模块，放在 `pkg` 下意味着它**不依赖业务逻辑**，甚至可以被其他项目引用。
*   **factory**: `BuildCommand("nmap", config)` -> 返回 `nmap -sS ...` 字符串。
*   **parser**: `ParseOutput("nmap", xmlData)` -> 返回标准化的 `StageResult` 结构体。

### 4. Model Layer (模型) -> `internal/model`
**Strictly structs.** 保持贫血模型。
*   所有 GORM 的 tag (`gorm:"..."`) 和 JSON tag (`json:"..."`) 都在这里定义。
*   不要在这里写业务逻辑。

## 迁移策略 (Migration Strategy)

1.  **Phase 1: Foundation (基础设施)**
    *   创建 `internal/pkg/tool_adapter`。这是无依赖的，最安全。
    *   完善 `internal/model` 中的 Structs (基于 ER 图)。

2.  **Phase 2: The Core (核心逻辑)**
    *   在 `internal/service/orchestrator` 下创建 `core` 目录。
    *   编写 `engine` (状态机)，并为其编写单元测试。

3.  **Phase 3: The Pipeline (数据流)**
    *   在 `internal/service/asset` 下创建 `pipeline` 目录。
    *   迁移现有的资产保存逻辑到 `merger.go`。

4.  **Phase 4: Integration (集成)**
    *   修改现有的 `service.go`，让它调用 `core` 和 `pipeline` 中的组件，而不是自己写满 `if/else`。


## 5. 迁移策略 (Phased Migration)

为了确保系统稳定性，我们按照 **"依赖倒置"** 的顺序进行迁移：

**Phase 1: 基础设施 (Infrastructure)**
- 创建 `internal/pkg/tool_adapter`。
- 实现 Nmap/Masscan 的命令生成器和解析器。
- **验证**：编写单元测试，确保解析逻辑正确。此时不触碰任何现有业务代码。

**Phase 2: 数据模型 (Data Model)**
- 更新 `internal/model` 下的 Structs，匹配新的 ER 图。
- 创建/更新 `internal/repo`。
- **验证**：运行 `go test` 确保数据库迁移脚本 (GORM AutoMigrate) 正常工作。

**Phase 3: 核心逻辑 (Core Logic)**
- 创建 `internal/service/orchestrator/core` 和 `internal/service/asset/pipeline`。
- 编写核心逻辑（状态机、数据合并）。
- **验证**：编写 Service 层单元测试。

**Phase 4: 接入层组装 (Wiring)**
- 修改现有的 `service/orchestrator/service.go`，让其调用 `core` 子模块。
- 修改现有的 `service/asset/service.go`，让其调用 `pipeline` 子模块。
- **验证**：启动 HTTP 服务，进行集成测试。

## 6. 总结

这种结构既保留了 Go 项目常见的 `internal/{handler,service,repo}` 顶层结构，符合团队既有习惯，又通过 **子包 (Sub-packages)** 的方式引入了必要的领域隔离。这是一种**实用主义**的重构方案。
