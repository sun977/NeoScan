# 资产与调度系统重构方案 (Linus's Taste Edition)

## 核心哲学
**"Bad programmers worry about the code. Good programmers worry about data structures."**
本重构方案基于 **State-Machine Based Pipeline (基于状态机的流水线架构)**，旨在消除传统 "Loop" 模式的复杂性，将系统解耦为职责单一、数据驱动的核心组件。

不再构建大而全的"统一配置中心"，而是实现以下具体的、可组合的原子组件。

## 1. 控制面 (Control Plane) - "大脑"

负责决策、调度与策略执行，不处理具体的大规模数据流。

### 1.1 Orchestrator (编排器)
*   **职责**: 系统的心脏。读取 `Project` 和 `Workflow` 定义，维护状态机，推动流程流转。
*   **核心组件**:
    *   **ScheduleManager**: 解析 Cron 表达式，定时触发 Project 执行。
    *   **StageTransitionEngine**: 状态机引擎。
        *   监听 Stage 完成事件。
        *   基于 `ScanStage` 表定义的规则，判断是否满足进入下一阶段的条件 (Next Stage Logic)。
        *   支持 DAG (有向无环图) 执行流。
    *   **TaskDispatcher**: 将逻辑上的 `ScanStage` 拆分为具体的 Task (Job)，分发给 Resource Allocator。

### 1.2 Policy Enforcer (策略执行器)
*   **职责**: 在任务下发前的最后一道防线，负责"安检"与合规。
*   **核心组件**:
    *   **WhitelistChecker**: 强制阻断。检查目标是否命中 `AssetWhitelist`。
        *   *原则*: 必须在 Master 端拦截，严禁将白名单目标下发给 Agent。
    *   **SkipLogicEvaluator**: 动态跳过。执行 `AssetSkipPolicy` 逻辑。
        *   *场景*: "如果是生产环境标签 && 当前时间是工作日 -> 跳过高风险扫描"。
    *   **ScopeValidator**: 范围校验。确保扫描目标严格限制在 Project 定义的 `TargetScope` 内，防止意外扫描互联网。

### 1.3 Resource Allocator (资源调度器)
*   **职责**: 管理 Agent 资源池，实现最优分配。
*   **核心组件**:
    *   **AgentSelector**: 智能匹配。
        *   基于 Capability (能力) 匹配: 只有安装了 Masscan 的 Agent 才能领 Masscan 任务。
        *   基于 Tag (标签) 匹配: 只有 "Zone:Inside" 的 Agent 才能扫内网。
    *   **RateLimiter**: 速率限制。
        *   全局限速: 防止 Master 被大量心跳打挂。
        *   目标限速: 防止把目标网段打挂。

---

## 2. 数据面 (Data Plane) - "流水线"

负责高吞吐的数据处理、清洗与存储。

### 2.1 Target Resolver (目标解析器)
*   **职责**: 解决"扫谁"的问题，将抽象的配置转换为具体的 IP/URL 列表。
*   **核心组件**:
    *   **StaticResolver**: 静态解析。处理 CIDR (`192.168.1.0/24`)、域名列表、IP 范围。
    *   **DynamicResolver (Pipeline Core)**: 动态解析。
        *   从 `AssetHost` / `AssetService` 表中查询**上一个阶段**的输出。
        *   *场景*: Stage 1 扫出 80 端口 -> Resolver 提取 IP:80 -> Stage 2 针对这些目标进行 Web 识别。

### 2.2 Result Ingestor (结果摄入器)
*   **职责**: 高吞吐地接收 Agent 的汇报，削峰填谷。
*   **核心组件**:
    *   **ResultQueue**: 缓冲队列 (Kafka / Redis List)。解耦 Agent 提交与 Master 处理速率。
    *   **ResultValidator**: 数据校验。验证 `StageResult` 的格式合法性、签名正确性。
    *   **EvidenceArchiver**: 原始证据归档。将 Agent 上报的原始 JSON/XML 存入对象存储 (S3/MinIO)，作为审计依据，永不篡改。

### 2.3 Asset ETL Engine (资产清洗引擎)
*   **职责**: 也就是 "Result Processor"。将碎片化的 `StageResult` 拼凑成完整的 `Asset` 视图。
*   **核心组件**:
    *   **Merger**: 状态合并逻辑。
        *   收到 "Port 80 Open" -> 查找 `AssetHost` -> 更新或插入 `AssetService` -> 更新 `LastSeen`。
    *   **FingerprintMatcher**: 指纹标准化。
        *   将 Nmap 的 "nginx 1.18" 和 Nuclei 的 "nginx/1.18.0" 统一映射为 CPE 标准格式。
    *   **WebCrawlerDataHandler**: 专用处理器。
        *   处理 `AssetWebDetail` 这种大体积、非结构化数据 (HTML body, Screenshots)。

---

## 3. 基础设施面 (Infrastructure Plane) - "基石"

### 3.1 Tool Adapter Layer (工具适配层)
*   **职责**: 将异构的扫描工具（Nmap, Masscan, Nuclei, Yakit）抽象为统一的系统能力。**工具是机制，不是策略。**
*   **核心组件**:
    *   **Tool Registry**: 工具注册表。
        *   管理工具的元数据、版本、Docker 镜像/二进制路径。
        *   支持 `ToolHealthCheck`，确保 Agent 端工具可用。
    *   **Command Factory (Master端)**: 命令工厂。
        *   **Template Engine**: 使用模板将 `ScanConfig` 转换为具体的 CLI 命令 (e.g., `nmap -sS -p {{.Ports}}`).
        *   **Argument Builder**: 动态注入参数 (如自动添加 `--exclude` 白名单参数)。
    *   **Output Normalizer (Agent/Master端)**: 结果标准化器。
        *   **Parsers**: 针对每种工具实现解析器 (XML/JSON/Text -> `StageResult`).
        *   **Standardization**: 统一字段命名 (e.g., 统一 `service_name`, `protocol`, `severity`)。

---

## 4. 重构路线图 (Implementation Path)

1.  **Phase 1: Data Structures First (已完成)**
    *   确立 `Asset*`, `ScanStage`, `StageResult` 等核心 ER 模型。

2.  **Phase 2: The Pipeline Core**
    *   实现 `Tool Adapter Layer` (Command Factory & Output Normalizer)。
    *   实现 `TaskDispatcher` 与 Agent 的通信协议。

3.  **Phase 3: The Brain**
    *   实现 `Orchestrator` 的状态机逻辑。
    *   实现 `Target Resolver` (Static & Dynamic)。

4.  **Phase 4: The Cleaner**
    *   实现 `Result Ingestor` 和 `Asset ETL Engine`。
    *   打通 "扫描 -> 结果 -> 资产" 的闭环。

5.  **Phase 5: Policy & Optimization**
    *   加入 `Policy Enforcer` (白名单/跳过策略)。
    *   优化 `Resource Allocator` (调度算法)。
